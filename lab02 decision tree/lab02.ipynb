{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16307110216 Ruian He"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data from downloaded files\n",
    "\n",
    "First we use `pandas` module to read from the csv file and take a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0    842302         M        17.99         10.38          122.80     1001.0   \n",
      "1    842517         M        20.57         17.77          132.90     1326.0   \n",
      "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
      "3  84348301         M        11.42         20.38           77.58      386.1   \n",
      "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
      "0  ...          17.33           184.60      2019.0            0.1622   \n",
      "1  ...          23.41           158.80      1956.0            0.1238   \n",
      "2  ...          25.53           152.50      1709.0            0.1444   \n",
      "3  ...          26.50            98.87       567.7            0.2098   \n",
      "4  ...          16.67           152.20      1575.0            0.1374   \n",
      "\n",
      "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
      "0             0.6656           0.7119                0.2654          0.4601   \n",
      "1             0.1866           0.2416                0.1860          0.2750   \n",
      "2             0.4245           0.4504                0.2430          0.3613   \n",
      "3             0.8663           0.6869                0.2575          0.6638   \n",
      "4             0.2050           0.4000                0.1625          0.2364   \n",
      "\n",
      "   fractal_dimension_worst  Unnamed: 32  \n",
      "0                  0.11890          NaN  \n",
      "1                  0.08902          NaN  \n",
      "2                  0.08758          NaN  \n",
      "3                  0.17300          NaN  \n",
      "4                  0.07678          NaN  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = '../breast_cancer/data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data\n",
    "\n",
    "As the diagnosis is a string, we must binarize the value for later calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df['diagnosis']=='M'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split the dataset into training and testing set using `sklearn` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (455,) (114, 30) (114,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[df.columns[2:-2]]\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model\n",
    "\n",
    "We take the ID3 algorithm with information gain as a criterion for choosing features. \n",
    "\n",
    "Information gain is the reduction in entropy or surprise by transforming a dataset and is often used in training decision trees. Information gain is calculated by comparing the entropy of the dataset before and after a transformation. \n",
    "\n",
    "\n",
    "And entropy, as it relates to machine learning, is a measure of the randomness in the information being processed and is defined as follows.\n",
    "\n",
    "![entropy](https://miro.medium.com/max/391/1*nNY_7_aWRwp8E2DyGduEPg.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DecisionTree(object):\n",
    "    class Node(object):\n",
    "        # the data \n",
    "        def __init__(self,sample_index,feature_index):\n",
    "            self.sample_index = sample_index\n",
    "            self.feature_index = feature_index\n",
    "\n",
    "            self.childs = []\n",
    "            self.predict = None\n",
    "            \n",
    "            self.gain = 0\n",
    "            self.feature = None\n",
    "            self.threshold = None \n",
    "        \n",
    "    def __init__(self, gain_threshold=1e-1):\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.root = None\n",
    "        \n",
    "        self.gain_threshold = gain_threshold\n",
    "        \n",
    "    def _entropy(self, y):\n",
    "        c = np.bincount(y)\n",
    "        p = c[np.nonzero(c)] / y.size\n",
    "        return -np.sum(p * np.log2(p))\n",
    "    \n",
    "    def _conditional_entropy(self, feature, y):\n",
    "        feature_values = np.unique(feature)\n",
    "        h = 0\n",
    "        for value in feature_values:\n",
    "            y_sub = y[feature == value]\n",
    "            h += y_sub.size / y.size * self._entropy(y_sub)\n",
    "        return h\n",
    "        \n",
    "    def _information_gain(self, feature, y):\n",
    "        return self._entropy(y) - self._conditional_entropy(feature,y)\n",
    "    \n",
    "    def _select_threshold(self, X, y, feature):\n",
    "        feature_values = np.unique(X[feature])\n",
    "        \n",
    "        best_gain = 0\n",
    "        best_threshold = None\n",
    "        for value in feature_values:\n",
    "            pred_feature = X[feature]>value\n",
    "            gain = self._information_gain(pred_feature,y)\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_threshold = value\n",
    "            \n",
    "        return best_threshold, best_gain\n",
    "    \n",
    "    def _select_feature(self, node):\n",
    "        X = self.X.loc[node.sample_index,node.feature_index]\n",
    "        y = self.y.loc[node.sample_index] \n",
    "        \n",
    "        for feature in node.feature_index:\n",
    "            threshold,gain = self._select_threshold(X, y, feature)\n",
    "            if gain > self.gain_threshold and gain > node.gain:\n",
    "                node.gain = gain\n",
    "                node.feature = feature\n",
    "                node.threshold = threshold\n",
    "                \n",
    "        return node.feature,node.threshold\n",
    "    \n",
    "    def _build_tree(self,node):\n",
    "        X = self.X.loc[node.sample_index,node.feature_index]\n",
    "        y = self.y.loc[node.sample_index]\n",
    "        \n",
    "        print(\"building node with %d examples...\"%(len(X.index)))\n",
    "        \n",
    "        feature,threshold = self._select_feature(node)\n",
    "        \n",
    "        if feature is not None:\n",
    "            feature_index = node.feature_index[:]\n",
    "            feature_index.remove(feature)\n",
    "            node.childs.append(self._build_tree(self.Node(X.index[X[feature] > threshold], feature_index)))\n",
    "            node.childs.append(self._build_tree(self.Node(X.index[X[feature] <= threshold],feature_index)))\n",
    "        else:\n",
    "            node.predict = np.argmax(np.bincount(y))\n",
    "            \n",
    "        return node\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        self.root = self.Node(list(X.index),list(X.columns))\n",
    "        self._build_tree(self.root)\n",
    "        \n",
    "        print(\"build complete!\")\n",
    "    \n",
    "    def _predict_node(self, x, node):\n",
    "        if node.feature is None:\n",
    "            return node.predict\n",
    "        elif x[node.feature] > node.threshold:\n",
    "            return self._predict_node(x, node.childs[0])\n",
    "        else:\n",
    "            return self._predict_node(x, node.childs[1])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return [self._predict_node(X.loc[index],self.root) for index in X.index]         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing\n",
    "\n",
    "Now we get the model and the data,then we can start training and testing.Moreover, we can look into accuracies in both classes and print the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building node with 455 examples...\n",
      "building node with 132 examples...\n",
      "building node with 125 examples...\n",
      "building node with 7 examples...\n",
      "building node with 4 examples...\n",
      "building node with 3 examples...\n",
      "building node with 323 examples...\n",
      "building node with 74 examples...\n",
      "building node with 41 examples...\n",
      "building node with 28 examples...\n",
      "building node with 22 examples...\n",
      "building node with 6 examples...\n",
      "building node with 3 examples...\n",
      "building node with 3 examples...\n",
      "building node with 13 examples...\n",
      "building node with 11 examples...\n",
      "building node with 2 examples...\n",
      "building node with 33 examples...\n",
      "building node with 5 examples...\n",
      "building node with 3 examples...\n",
      "building node with 2 examples...\n",
      "building node with 28 examples...\n",
      "building node with 249 examples...\n",
      "build complete!\n",
      "The model accuracy is: 0.9122807017543859\n",
      "The f1 score is: 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "model = DecisionTree()\n",
    "model.train(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"The model accuracy is:\",accuracy_score(y_test,y_pred))\n",
    "print(\"The f1 score is:\",f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(cm,cmap=plt.cm.Blues)\n",
    "\n",
    "ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=range(10), yticklabels=range(10),\n",
    "           title='Confusion Matrix',\n",
    "           ylabel='Actual',\n",
    "           xlabel='Predicted')\n",
    "\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, \n",
    "                s = format(int(cm[i, j]*100 + 0.5) , 'd') + '%', \n",
    "                ha = \"center\", \n",
    "                va = \"center\", \n",
    "                color = \"white\"  if cm[i, j] > 0.5 else \"black\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can look at the structure of the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Digraph.gv'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "from time import time\n",
    "from pickle import dump\n",
    "\n",
    "def build_tree(graph,node):\n",
    "    name = str(time()) \n",
    "    if node.feature is None:\n",
    "        graph.node(name = name, label = 'predict:'+str(node.predict)+'\\nnum:'+str(len(node.sample_index)))\n",
    "    else:\n",
    "        graph.node(name = name, label = 'feature:'+str(node.feature)+'\\nnum:'+str(len(node.sample_index))+' gain:%.2f'%(node.gain))\n",
    "        lchild = build_tree(graph,node.childs[0])\n",
    "        rchild = build_tree(graph,node.childs[1])\n",
    "        graph.edge(name,lchild,label='>%.2f'%(node.threshold))\n",
    "        graph.edge(name,rchild,label='<=%.2f'%(node.threshold))\n",
    "    return name\n",
    "graph = Digraph()\n",
    "build_tree(graph,model.root)\n",
    "graph.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
